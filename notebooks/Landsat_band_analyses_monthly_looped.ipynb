{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat_band_analyses_monthly_looped.ipynb\n",
    "\n",
    "\n",
    "This code outputs csv files of statistics for each analysis, as well as plots showing the relative statistical significance of each analysis, for each case study site.\n",
    "\n",
    "Written by Claire Krause, January 2017, Datacube v 1.13\n",
    "\n",
    "** Code dependencies **\n",
    "- csv file containing the bounding boxes for the case study site/s\n",
    "- palaeovalleys 2012 shape file\n",
    "- Landsat band average netcdf files produced by \"Extract_AGDC_for_study_sites_looped\"\n",
    "\n",
    "**Accompanying code**\n",
    "- Landsat_band_analyses.ipynb - The accompanying notebook shows what each step in this notebook does, and should be referred to for more detailed explanations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the libraries we need in the code and tell matplotlib to display the plots here\n",
    "%matplotlib inline\n",
    "import fiona\n",
    "import shapely.geometry\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import geopandas as gp\n",
    "import datacube\n",
    "datacube.set_options(reproject_threads=1)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import scipy.stats\n",
    "import pandas\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up some functions to use later in the code\n",
    "def warp_geometry(geom, src_crs, dst_crs):\n",
    "    \"\"\"\n",
    "    warp geometry from src_crs to dst_crs\n",
    "    \"\"\"\n",
    "    return shapely.geometry.shape(rasterio.warp.transform_geom(src_crs, dst_crs, shapely.geometry.mapping(geom)))\n",
    "\n",
    "def geometry_mask(geom, geobox, all_touched=False, invert=False):\n",
    "    \"\"\"\n",
    "    rasterize geometry into a binary mask where pixels that overlap geometry are False\n",
    "    \"\"\"\n",
    "    return rasterio.features.geometry_mask([geom],\n",
    "                                           out_shape=geobox.shape,\n",
    "                                           transform=geobox.affine,\n",
    "                                           all_touched=all_touched,\n",
    "                                           invert=invert)\n",
    "def write_to_csv(OUTPUT_path, row, site):\n",
    "    if site == 'Blackwood2A':\n",
    "        with open(OUTPUT_path,'w') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            header = ['name', 'ttest', 'KS_test']\n",
    "            writer.writerow(header)\n",
    "            writer.writerow(row)\n",
    "    else:\n",
    "        with open(OUTPUT_path,'a') as csvFile:\n",
    "           writer = csv.writer(csvFile)\n",
    "           writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in our list of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name     minlat     maxlat      minlon      maxlon\n",
      "0   Blackwood2A -34.100000 -33.400000  116.400000  117.400000\n",
      "1   Blackwood2B -34.100000 -33.400000  117.400000  118.400000\n",
      "2   Blackwood2C -33.400000 -32.700000  116.400000  117.400000\n",
      "3   Blackwood2D -33.400000 -32.700000  117.400000  118.400000\n",
      "4      GarfordA -29.900000 -29.230000  133.150000  133.925000\n",
      "5      GarfordB -29.900000 -29.230000  133.925000  134.700000\n",
      "6     Mandora1A -21.100000 -20.356667  120.900000  121.916667\n",
      "7     Mandora1B -21.100000 -20.356667  121.916667  122.933333\n",
      "8     Mandora1C -21.100000 -20.356667  122.933333  123.950000\n",
      "9     Mandora1D -21.100000 -20.356667  123.950000  124.966667\n",
      "10    Mandora1E -21.100000 -20.356667  124.966667  125.983333\n",
      "11    Mandora1F -21.100000 -20.356667  125.983333  127.000000\n",
      "12    Mandora1G -20.356667 -19.613333  120.900000  121.916667\n",
      "13    Mandora1H -20.356667 -19.613333  121.916667  122.933333\n",
      "14    Mandora1I -20.356667 -19.613333  122.933333  123.950000\n",
      "15    Mandora1J -20.356667 -19.613333  123.950000  124.966667\n",
      "16    Mandora1K -20.356667 -19.613333  124.966667  125.983333\n",
      "17    Mandora1L -20.356667 -19.613333  125.983333  127.000000\n",
      "18    Mandora1M -19.613333 -18.870000  120.900000  121.916667\n",
      "19    Mandora1N -19.613333 -18.870000  121.916667  122.933333\n",
      "20    Mandora1O -19.613333 -18.870000  122.933333  123.950000\n",
      "21    Mandora1P -19.613333 -18.870000  123.950000  124.966667\n",
      "22    Mandora1Q -19.613333 -18.870000  124.966667  125.983333\n",
      "23    Mandora1R -19.613333 -18.870000  125.983333  127.000000\n",
      "24    Mandora2A -20.030000 -19.455000  120.900000  122.100000\n",
      "25    Mandora2B -19.455000 -18.880000  120.900000  122.100000\n",
      "26    Mandora2C -20.030000 -19.455000  122.100000  123.300000\n",
      "27    Mandora2D -19.455000 -18.880000  122.100000  123.300000\n",
      "28   MurchisonA -27.950000 -27.130000  114.750000  115.887500\n",
      "29   MurchisonB -27.130000 -26.310000  114.750000  115.887500\n",
      "30   MurchisonC -26.310000 -25.490000  114.750000  115.887500\n",
      "31   MurchisonD -27.950000 -27.130000  115.887500  117.025000\n",
      "32   MurchisonE -27.130000 -26.310000  115.887500  117.025000\n",
      "33   MurchisonF -26.310000 -25.490000  115.887500  117.025000\n",
      "34   MurchisonG -27.950000 -27.130000  117.025000  118.162500\n",
      "35   MurchisonH -27.130000 -26.310000  117.025000  118.162500\n",
      "36   MurchisonI -26.310000 -25.490000  117.025000  118.162500\n",
      "37   MurchisonJ -27.950000 -27.130000  118.162500  119.300000\n",
      "38   MurchisonK -27.130000 -26.310000  118.162500  119.300000\n",
      "39   MurchisonL -26.310000 -25.490000  118.162500  119.300000\n",
      "40          Ord -15.930000 -15.050000  128.300000  129.290000\n",
      "41      TiTreeA -23.040000 -22.355000  133.180000  134.240000\n",
      "42      TiTreeB -22.355000 -21.670000  133.180000  134.240000\n",
      "43     Daintree -16.390000 -16.090000  145.210000  145.420000\n",
      "44       LauraA -15.850000 -14.430000  143.420000  144.155000\n",
      "45       LauraB -15.850000 -14.430000  144.155000  144.890000\n",
      "46  Blackwood1A -34.400000 -33.580000  115.000000  115.700000\n",
      "47  Blackwood1B -34.400000 -33.580000  115.700000  116.400000\n",
      "48      Testing -23.000000 -22.950000  133.100000  133.150000\n"
     ]
    }
   ],
   "source": [
    "# Set up the case study bounding box (to make the file smaller and avoid memory errors)\n",
    "# Read in a csv file with all case study bounding boxes\n",
    "names = pandas.read_csv('/g/data/p25/cek156/case_study_sites_small.csv', delimiter = ',')\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the palaeovalley 2012 mask. \n",
    "This code reads in the shapefile and identifies and lists all of the polygons witin it. For this example, we are using the 2012 Palaeovalleys shape file (see English et al. 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                               geometry\n",
      "0    POLYGON ((123.648953793 -30.56992565499991, 12...\n",
      "1    (POLYGON ((117.1778376770001 -32.2709919609999...\n",
      "2    POLYGON ((115.868565061 -29.73637336599995, 11...\n",
      "3    POLYGON ((115.948200584 -27.86854227199996, 11...\n",
      "4    POLYGON ((127.387641593 -28.59592641999996, 12...\n",
      "5    POLYGON ((128.0569520910001 -28.54635345199995...\n",
      "6    POLYGON ((128.698006552 -26.21770164599991, 12...\n",
      "7    POLYGON ((126.722619924 -22.32913755999994, 12...\n",
      "8    POLYGON ((128.3006654730001 -18.96357787199992...\n",
      "9    POLYGON ((115.3584853260001 -27.20097888599992...\n",
      "10   POLYGON ((126.9556900690001 -26.30121716599996...\n",
      "11   POLYGON ((115.8733712540001 -25.14138591099993...\n",
      "12   POLYGON ((125.9475394960001 -28.62771558199995...\n",
      "13   POLYGON ((124.9745967660001 -29.53551659999994...\n",
      "14   POLYGON ((120.9398331570001 -19.64230130599992...\n",
      "15   POLYGON ((128.361469574 -22.02882464999993, 12...\n",
      "16   POLYGON ((123.9446491120001 -31.16821603799991...\n",
      "17   POLYGON ((120.6515032970001 -30.17781687399992...\n",
      "18   POLYGON ((121.3875848570001 -30.32992431799994...\n",
      "19   POLYGON ((122.144377404 -31.53821969799992, 12...\n",
      "20   POLYGON ((123.7501057540001 -27.82197962499993...\n",
      "21   POLYGON ((115.9123264670001 -28.67849277999994...\n",
      "22   POLYGON ((117.109065446 -31.62277772699991, 11...\n",
      "23   POLYGON ((117.520863186 -33.8667393849999, 117...\n",
      "24   POLYGON ((116.4432519010001 -33.64107156899991...\n",
      "25   POLYGON ((122.0541877400001 -19.1703829889999,...\n",
      "26   POLYGON ((117.0923601080001 -32.59785196199994...\n",
      "27   POLYGON ((115.540594457 -21.98219002099995, 11...\n",
      "28   POLYGON ((123.0788711790001 -24.97706896899996...\n",
      "29   POLYGON ((121.020780833 -20.07421933799992, 12...\n",
      "..                                                 ...\n",
      "204  POLYGON ((117.1147080070001 -31.60533708599991...\n",
      "205  POLYGON ((115.8728616100001 -25.15896860599992...\n",
      "206  POLYGON ((119.189236248 -32.10666214099996, 11...\n",
      "207  POLYGON ((121.2658512410001 -33.50697276099993...\n",
      "208  POLYGON ((121.145450514 -33.51363525199991, 12...\n",
      "209  POLYGON ((121.104999677 -33.56446053899992, 12...\n",
      "210  POLYGON ((121.1280328590001 -33.79698146799996...\n",
      "211  POLYGON ((120.9801017680001 -33.7944116509999,...\n",
      "212  POLYGON ((120.8541687950001 -33.82057382499994...\n",
      "213  POLYGON ((120.8414981650001 -33.66965650999992...\n",
      "214  POLYGON ((120.7829634240001 -33.63760516999992...\n",
      "215  POLYGON ((120.726927118 -33.63617749299993, 12...\n",
      "216  POLYGON ((120.764691521 -33.71517282299993, 12...\n",
      "217  POLYGON ((120.637628303 -33.67020100999991, 12...\n",
      "218  POLYGON ((120.664754159 -33.59881717999991, 12...\n",
      "219  POLYGON ((120.6160346950001 -33.57597435399992...\n",
      "220  POLYGON ((120.588195001 -33.52814718799993, 12...\n",
      "221  POLYGON ((120.5649952560001 -33.53528557099992...\n",
      "222  POLYGON ((120.5403678350001 -33.55384536699995...\n",
      "223  POLYGON ((120.55246663 -33.61133032499993, 120...\n",
      "224  POLYGON ((120.035750115 -33.87489198899993, 12...\n",
      "225  POLYGON ((120.0351790450001 -33.77352695099995...\n",
      "226  POLYGON ((120.6358739750001 -33.37047599899995...\n",
      "227  POLYGON ((120.7706109550001 -33.45506583799994...\n",
      "228  POLYGON ((121.5874452190001 -33.33423253099994...\n",
      "229  POLYGON ((121.5881549070001 -33.35619578899991...\n",
      "230  POLYGON ((121.0923378780001 -33.43698193499995...\n",
      "231  POLYGON ((118.376390621 -34.47134306099991, 11...\n",
      "232  POLYGON ((121.644767752 -33.47144425499994, 12...\n",
      "233  POLYGON ((120.236120258 -33.79465200299995, 12...\n",
      "\n",
      "[234 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "shp = gp.GeoDataFrame.from_file('/g/data/p25/cek156/Palaeovalleys_2012.shp')\n",
    "print (shp.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the statistics for each site\n",
    "\n",
    "Loop through each case study site, calculate a series of band analyses, apply the palaeovalleys 2012 mask, calculate the statistical difference in values inside and outside the masked areas, then write the results to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Blackwood2A\n",
      "Applying datacube geobox\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dimensions () must have the same length as the number of data dimensions, ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-8905ac6500a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeometry_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarp_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshp_union\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeobox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m# Get data only where the mask is 'true'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mdata_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;31m# Get data only where the mask is 'false'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mdata_maskedF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20161201/envs/agdc/lib/python3.5/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, drop)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0moutcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;31m# this has no runtime function - these are listed so IDEs know these methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20161201/envs/agdc/lib/python3.5/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m             variable = (f(self.variable, other_variable)\n\u001b[0;32m-> 1300\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m                         else f(other_variable, self.variable))\n\u001b[1;32m   1302\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20161201/envs/agdc/lib/python3.5/site-packages/xarray/core/ops.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20161201/envs/agdc/lib/python3.5/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     def reduce(self, func, dim=None, axis=None, keep_attrs=False,\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20161201/envs/agdc/lib/python3.5/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1046\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m                         else f(other_data, self_data))\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20161201/envs/agdc/lib/python3.5/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims, data, attrs, encoding, fastpath)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_compatible_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20161201/envs/agdc/lib/python3.5/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m_parse_dimensions\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    340\u001b[0m             raise ValueError('dimensions %s must have the same length as the '\n\u001b[1;32m    341\u001b[0m                              \u001b[0;34m'number of data dimensions, ndim=%s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                              % (dims, self.ndim))\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimensions () must have the same length as the number of data dimensions, ndim=2"
     ]
    }
   ],
   "source": [
    "for num, site in enumerate(names.Name):\n",
    "    print ('Working on ' + site)\n",
    "    # Set up our file names to be read in\n",
    "    blue_mean = '/g/data/p25/cek156/' + site + '/' + site + '_bluemonthly_time_mean.nc'\n",
    "    green_mean = '/g/data/p25/cek156/' + site + '/' + site + '_greenmonthly_time_mean.nc'\n",
    "    red_mean = '/g/data/p25/cek156/' + site + '/' + site + '_redmonthly_time_mean.nc'\n",
    "    nir_mean = '/g/data/p25/cek156/' + site + '/' + site + '_nirmonthly_time_mean.nc'\n",
    "    swir1_mean = '/g/data/p25/cek156/' + site + '/' + site + '_swir1monthly_time_mean.nc'\n",
    "    swir2_mean = '/g/data/p25/cek156/' + site + '/' + site + '_swir2monthly_time_mean.nc'\n",
    "    \n",
    "    # We need to check that the mean files have been created before we try to read them in\n",
    "    file_checkb = os.path.isfile(blue_mean)\n",
    "    file_checkg = os.path.isfile(green_mean)\n",
    "    file_checkr = os.path.isfile(red_mean)\n",
    "    file_checkn = os.path.isfile(nir_mean)\n",
    "    file_checks1 = os.path.isfile(swir1_mean)\n",
    "    file_checks2 = os.path.isfile(swir2_mean)\n",
    "    \n",
    "    # If all the files are then, then we can read them in\n",
    "    if file_checkb == True & file_checkg == True & file_checkr == True & file_checkn == True & file_checks1 == True & file_checks2 == True:\n",
    "        blue = xr.open_dataset(blue_mean)\n",
    "        green = xr.open_dataset(green_mean)\n",
    "        red = xr.open_dataset(red_mean)\n",
    "        nir = xr.open_dataset(nir_mean)\n",
    "        swir1 = xr.open_dataset(swir1_mean) \n",
    "        swir2 = xr.open_dataset(swir2_mean)\n",
    "\n",
    "        ########### Set up the analyses you would like to do ###########################\n",
    "        # Check out http://www.indexdatabase.de/db/i.php for a list of a whole bunch of indices, \n",
    "        # as well as their platform specific formulas (if you click on the index name).\n",
    "        analyses = {'only_blue':blue.blue,\n",
    "        'only_green':green.green,\n",
    "        'only_red':red.red,\n",
    "        'only_nir':nir.nir,\n",
    "        'only_swir1':swir1.swir1,\n",
    "        'only_swir2':swir2.swir2,\n",
    "        'greenness':(green.green / red.red),\n",
    "        'drought':(swir2.swir2 / nir.nir),\n",
    "        'ferrous':(swir1.swir1 / nir.nir),\n",
    "        'clay':(swir1.swir1 / swir2.swir2),\n",
    "        'soilBG':(nir.nir - (2.4 * red.red)), # Soil background line\n",
    "        'soilComp':((swir1.swir1 - nir.nir) / (swir1.swir1 + nir.nir)), # Soil composition index\n",
    "        'SAVI':(((nir.nir - red.red) / (nir.nir + red.red + 0.5))*(1 + 0.5)), #Soil adjusted vegetation index, where L = 0.5\n",
    "        'FalseCol':((nir.nir + red.red + green.green)), #False colour\n",
    "        'RealCol':((red.red + green.green + blue.blue)), #Real colour\n",
    "        'NDMI':((nir.nir - swir1.swir1) / (nir.nir + swir1.swir1)), #normalised difference moisture index\n",
    "        'NDSI':((swir1.swir1 - swir2.swir2) / (swir1.swir1 + swir2.swir2))} # normalised difference salinity index\n",
    "        ################################################################################\n",
    "\n",
    "        for method in analyses:\n",
    "            \n",
    "            data = analyses[method]\n",
    "                        \n",
    "            ## Choose the time periods for the analysis\n",
    "            times = {'DJF':(11, 0, 1),\n",
    "                     'MAM':(2, 3, 4),\n",
    "                     'JJA':(5, 6, 7), \n",
    "                     'SON':(8, 9, 10),\n",
    "                     'first6':(0, 1, 2, 3, 4, 5),\n",
    "                     'last6': (6, 7, 8, 9, 10, 11)}\n",
    "            \n",
    "            for time in times:\n",
    "                data = data.isel(month = times[time]).mean()\n",
    "                \n",
    "                OUTPUT = '/g/data/p25/cek156/Landsat/' + method + '_' + time + '_monthly_stats.csv'\n",
    "                \n",
    "                # Create a bounding box from the locations specified above\n",
    "                box = shapely.geometry.box(names.minlon[num], names.minlat[num], names.maxlon[num], names.maxlat[num], ccw = True)\n",
    "                # Only get the polygons that intersect the bounding box (i.e. remove all the irrelevant ones)\n",
    "                filtered = shp.where(shp.intersects(box)).dropna()\n",
    "                # Combine all of the relevant polygons into a single polygon\n",
    "                shp_union = shapely.ops.unary_union(filtered.geometry)\n",
    "\n",
    "                # Check for the geobox attribute. If it's not there, apply it from the datacube.\n",
    "                if not hasattr(data, 'geobox'):\n",
    "                    query = {'time': ('2000-01-01', '2000-01-31'),\n",
    "                             'lat': (names.maxlat[num], names.minlat[num]), \n",
    "                             'lon': (names.minlon[num], names.maxlon[num]), \n",
    "                             'resolution': (-250, 250)}\n",
    "                    bands_of_interest = [#'blue',\n",
    "                                         #'green',\n",
    "                                         'red', \n",
    "                                         #'nir',\n",
    "                                         #'swir1', \n",
    "                                         #'swir2',\n",
    "                                         ]\n",
    "                    dc = datacube.Datacube(app='hack')\n",
    "                    nbar = dc.load(product = 'ls7_nbar_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "                    print('Applying datacube geobox')\n",
    "                    geobox = nbar.geobox\n",
    "                # Create the mask based on our shapefile\n",
    "                mask = geometry_mask(warp_geometry(shp_union, shp.crs, blue.crs), geobox, invert=True)\n",
    "                # Get data only where the mask is 'true'\n",
    "                data_masked = data.where(mask)\n",
    "                # Get data only where the mask is 'false'\n",
    "                data_maskedF = data.where(~ mask)\n",
    "\n",
    "                ## Now check for statistical significance\n",
    "                # Create a new numpy array with just the slope values\n",
    "                data_masked2 = np.array(data_masked)\n",
    "                data_maskedF2 = np.array(data_maskedF)\n",
    "                # Remove nan values\n",
    "                data_masked_nonan = data_masked2[~np.isnan(data_masked2)]\n",
    "                data_maskedF_nonan = data_maskedF2[~np.isnan(data_maskedF2)]\n",
    "                masked_both = [data_masked_nonan,data_maskedF_nonan]\n",
    "                if data_masked_nonan.any():\n",
    "                    # How many data points are in each of my NDVI lists?\n",
    "                    size = ([len(i) for i in masked_both])\n",
    "                    # Test with a t-test\n",
    "                    stats_ttest, ttest_pval = scipy.stats.ttest_ind(data_masked_nonan,data_maskedF_nonan, equal_var = 'False')\n",
    "                    # Test with a Kolmogorov-Smirnov test \n",
    "                    # Our null hypothesis that 2 independent samples are drawn from the same continuous distribution\n",
    "                    stats_KS, KS_pval = scipy.stats.ks_2samp(data_masked_nonan,data_maskedF_nonan)\n",
    "\n",
    "                    # Write to csv file\n",
    "                    row = [site, stats_ttest, stats_KS]\n",
    "                    # Write our stats to a csv file so we can compare them later\n",
    "                    # If this is the first site, make a new file, otherwise, append the existing file\n",
    "                    print('writing to csv')\n",
    "                    write_to_csv(OUTPUT, row, site)\n",
    "                    # Or if there is no data...\n",
    "                else:\n",
    "                    print('no useful data')\n",
    "                    row = [site, 'nan', 'nan']\n",
    "                    write_to_csv(OUTPUT, row, site)\n",
    "            # Or if there is no data...\n",
    "        else:\n",
    "            print('No mean files yet for' + site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'green' ()>\n",
      "array(777.5152215722015)\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the csv files and prepare for plotting\n",
    "\n",
    "At this stage, the smaller chunks of each case study area still have their own statistics. We want to know what the solution is over the whole bounding box, so we will average the stats together here to give us just one output for each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "study_sites = pandas.read_csv('/g/data/p25/cek156/case_study_sites.csv')\n",
    "\n",
    "for method in analyses:\n",
    "    #Read in the CSVs\n",
    "    for time in times:\n",
    "        data = data.groupby(times[time]).mean()\n",
    "\n",
    "        OUTPUT = '/g/data/p25/cek156/Landsat/' + method + '_' + time + '_monthly_stats.csv'\n",
    "        print('Working on ' + method)\n",
    "        method_stats = pandas.read_csv(OUTPUT)\n",
    "\n",
    "        mean_values = pandas.DataFrame(columns = ['Site', 'ttest_mean', 'KS_mean'])\n",
    "\n",
    "        exclude_last_three = study_sites[:-3]\n",
    "        for idx, site in enumerate(exclude_last_three.Name):\n",
    "            ttest_mean = method_stats[method_stats.name.str.contains(site)].ttest.mean()\n",
    "            ks_mean = method_stats[method_stats.name.str.contains(site)].KS_test.mean()\n",
    "            mean_values.loc[idx] = [site, ttest_mean, ks_mean]\n",
    "\n",
    "        # Setting the positions and width for the bars\n",
    "        pos = list(range(len(mean_values.ttest_mean)))\n",
    "        width = 0.25\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "        ax2 = ax.twinx() # Create another axes that shares the same x-axis as ax.\n",
    "\n",
    "        mean_values.KS_mean.plot(kind='bar', color='red', ax=ax, width=width, position=1)\n",
    "        mean_values.ttest_mean.plot(kind='bar', color='blue', ax=ax2, width=width, position=0)\n",
    "\n",
    "        # Set the y axis label\n",
    "        ax.set_ylabel('KS test statistic', color='red')\n",
    "        ax2.set_ylabel('t test statistic', color='blue')\n",
    "\n",
    "        # Set the labels for the x ticks\n",
    "        ax.set_xticklabels(mean_values['Site'])\n",
    "\n",
    "        # Setting the x-axis and y-axis limits\n",
    "        ax2.set_ylim([150, -150])\n",
    "        ax.set_ylim([1, -1])\n",
    "\n",
    "        #Let's save the plot\n",
    "        fig.savefig('/g/data/p25/cek156/Landsat/' + method + '_' + time + '_stats.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
